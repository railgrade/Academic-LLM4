# Instruction Tuning

Table of Content

- [Papers](#papers)
- [Blogs](#blogs)
- [Reference](#reference)

## Papers

Survey

- [2023-07] Aligning Large Language Models with Human: A Survey, [paper](https://arxiv.org/abs/2307.12966), [github](https://github.com/GaryYufei/AlignLLMHumanSurvey)

Reading List

| Title                                                                                          | Pub          | Date                                          | Supplementary                                                          |
| ---------------------------------------------------------------------------------------------- | ------------ | --------------------------------------------- | ---------------------------------------------------------------------- |
| How Far Can Camels Go? Exploring the State of Instruction Tuning on Open Resources             |              | [2306.04751](https://arxiv.org/abs/2306.04751)   | [open-instruct](https://github.com/allenai/open-instruct) (code), AI2     |
| LI